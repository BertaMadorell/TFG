{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264e771a",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, sampler, random_split\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import wandb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24dd4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mb-madorell\u001b[0m (\u001b[33mb-madorell-universitat-de-girona\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/bertam/CHALLENGE/wandb/run-20250514_204606-82bxsrt2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/b-madorell-universitat-de-girona/AP%20arreglemho/runs/82bxsrt2' target=\"_blank\">stilted-valley-1</a></strong> to <a href='https://wandb.ai/b-madorell-universitat-de-girona/AP%20arreglemho' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/b-madorell-universitat-de-girona/AP%20arreglemho' target=\"_blank\">https://wandb.ai/b-madorell-universitat-de-girona/AP%20arreglemho</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/b-madorell-universitat-de-girona/AP%20arreglemho/runs/82bxsrt2' target=\"_blank\">https://wandb.ai/b-madorell-universitat-de-girona/AP%20arreglemho/runs/82bxsrt2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/b-madorell-universitat-de-girona/AP%20arreglemho/runs/82bxsrt2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7feee7c56630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "wandb.init(project=\"AP arreglemho\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b407f40",
   "metadata": {},
   "source": [
    "## CLASSES AND FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom Dataset class that loads images and their corresponding labels from a DataFrame.\n",
    "    Each row in the DataFrame should contain the image file path and its label.\n",
    "    Applies image transformations using torchvision transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        Input:\n",
    "            dataframe: DataFrame containing image paths and labels.\n",
    "            transform: Optional transformations to apply to each image.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single sample from the dataset.\n",
    "        Input:\n",
    "            idx: Index of the sample to retrieve.\n",
    "\n",
    "        Output:\n",
    "                image_tensor: Transformed image.\n",
    "                label: Ground truth label (0 or 1).\n",
    "                filename: Base name of the image file.\n",
    "        \"\"\"\n",
    "        img_path = self.dataframe.iloc[idx, 0]  # Get image file path\n",
    "        image = Image.open(img_path).convert('RGB')  # Open and convert to RGB\n",
    "        label = self.dataframe.iloc[idx, 1]  # Get label (0 or 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply data transformations\n",
    "        \n",
    "        return image, label, os.path.basename(img_path)  # Return image, label, filename\n",
    "        return image, label, os.path.basename(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aea99b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72af4ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = {'train_transforms' : transforms.Compose([\n",
    "    transforms.Resize(256),  # Redimensiona la part curta a 256\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=mean)\n",
    "]),\n",
    "'val_transforms' : transforms.Compose([\n",
    "    transforms.Resize(256),          # Redimensiona la part curta a 256\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]),\n",
    "'test_transforms' : transforms.Compose([\n",
    "    transforms.Resize(256),          # Redimensiona la part curta a 256\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44186434",
   "metadata": {},
   "source": [
    "Model and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a883d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom neural network model based on a pretrained ResNet50 for binary classification (Pneumonia detection).\n",
    "\n",
    "    - Replaces the ResNet50 classifier with a custom fully connected head.\n",
    "    - Freezes early layers to focus training on higher-level features and make fine tunning.\n",
    "    - Includes methods for forward propagation and model training with early stopping and learning rate scheduling.\n",
    "    - Training metrics and performance are logged using Weights & Biases (wandb).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the model by:\n",
    "        - Loading a pretrained ResNet50.\n",
    "        - Replacing the default classifier with a custom sequential classifier suited for binary classification.\n",
    "        - Freezing all layers except 'layer4' and the classifier to fine-tune only the last layers.\n",
    "        \"\"\"\n",
    "        # Load pretrained ResNet50\n",
    "        super(Model, self).__init__()\n",
    "        self.model = torchvision.models.resnet50(pretrained=True)\n",
    "        # Replace the default classifier with a custom one\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 512),  # Reduces characteristics to 512\n",
    "            nn.ReLU(),  # Activates the neurons in a non linear way\n",
    "            nn.Dropout(0.4),  # Reduces overfitting by eliminating connections in each forward pass\n",
    "            nn.Linear(512, 2)  # Reduces to 2 classes (Pneumonia or No Pneumonia)\n",
    "            #nn.LogSoftmax(dim=1)  # Converts the outputs into logarithmic probabilities\n",
    "        )\n",
    "\n",
    "        # Freeze early layers except 'layer4' and the classifier\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"layer4\" not in name and \"fc\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Replace the original fully connected layer\n",
    "        self.model.fc = self.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "        Input: tensor (image batch).\n",
    "        Output: logits for classification.\n",
    "        \"\"\"\n",
    "        return self.model(x)   \n",
    "    \n",
    "    def fit(self, dataloaders, num_epochs):\n",
    "        \"\"\"\n",
    "        Trains the model using a given number of epochs with early stopping and learning rate scheduling.\n",
    "\n",
    "        - Uses separate learning rates for the last ResNet block (layer 4) and the classifier.\n",
    "        - Applies gradient clipping to stabilize training.\n",
    "        - Logs training and validation metrics (loss and accuracy) to wandb.\n",
    "        - Saves the best model weights based on validation accuracy.\n",
    "\n",
    "        Input: \n",
    "            dataloaders: Containing 'train' and 'val' DataLoaders.\n",
    "            num_epochs: Number of epochs to train the model.\n",
    "\n",
    "        Returns: The trained model with the best validation performance.\n",
    "        \"\"\"\n",
    "        train_on_gpu = torch.cuda.is_available()\n",
    "        # Optimizer with separate learning rates for the final layers\n",
    "        optimizer = optim.Adam(\n",
    "            [\n",
    "                {\"params\": self.model.layer4.parameters(), \"lr\": 1e-4},  # Smaller learning rate\n",
    "                {\"params\": self.model.fc.parameters(), \"lr\": 1e-3}       # Bigger learning rate\n",
    "            ]\n",
    "        )\n",
    "        # Learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2)  # Based in val_acc\n",
    "        # Loss function\n",
    "        criterion = nn.CrossEntropyLoss()  # Better than NLLLoss\n",
    "        \n",
    "        since = time.time()  \n",
    "        patience = 10\n",
    "        counter = 0      \n",
    "        \n",
    "        # Save the best model weights\n",
    "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        best_acc = 0.0\n",
    "        if train_on_gpu:\n",
    "            self.model = self.model.to(device)\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(\"epoch {}/{}\".format(epoch, num_epochs))\n",
    "            print(\"-\" * 10)            \n",
    "            \n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    self.model.train()\n",
    "                else:\n",
    "                    self.model.eval()                \n",
    "                    \n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0.0                \n",
    "                \n",
    "                for inputs, labels, _ in dataloaders[phase]:\n",
    "                    if train_on_gpu:\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                    optimizer.zero_grad()                    \n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = self.model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)                        \n",
    "                        \n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                            optimizer.step() \n",
    "                            \n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)                \n",
    "                    \n",
    "                epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)                \n",
    "                \n",
    "                # We send the metrics to Weights & Biases\n",
    "                if phase == 'train':\n",
    "                    wandb.log({\"Train Loss\": epoch_loss, \"Train Accuracy\": epoch_acc, \"epoch\": epoch})\n",
    "                else:\n",
    "                    wandb.log({\"Validation Loss\": epoch_loss, \"Validation Accuracy\": epoch_acc, \"epoch\": epoch})                \n",
    "                    \n",
    "                print(\"{} loss:  {:.4f}  acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))               \n",
    "                \n",
    "                # Early stopping based on validation accuracy\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                \n",
    "                    if epoch_acc > best_acc:\n",
    "                        best_acc = epoch_acc\n",
    "                        best_model_wts = copy.deepcopy(self.model.state_dict())        \n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                    \n",
    "                    if counter >= patience:\n",
    "                        print(\"ðŸ›‘ Early stopping activat!\")\n",
    "                        self.model.load_state_dict(best_model_wts)  # Get the best model\n",
    "                        return self.model\n",
    "                    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('time completed: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print(\"best val acc: {:.4f}\".format(best_acc))        \n",
    "        \n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eee944",
   "metadata": {},
   "source": [
    "Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810446da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img, mean, std):\n",
    "    \"\"\"\n",
    "    Reverts the normalization applied to an image tensor and ensures pixel values are in [0, 1].\n",
    "\n",
    "    Input:\n",
    "        img : A normalized image as a NumPy array of shape (C, H, W), where C is the number of channels.\n",
    "        mean : The mean values used during normalization, one for each channel.\n",
    "        std : The standard deviation values used during normalization, one for each channel.\n",
    "    \n",
    "    Output: The denormalized image as a NumPy array with pixel values clipped to the range [0, 1].\n",
    "    \"\"\"\n",
    "    mean = np.array(mean)\n",
    "    std = np.array(std)\n",
    "\n",
    "    # Reverse the normalization: x_original = x_normalized * std + mean\n",
    "    img = img * std[:, None, None] + mean[:, None, None]\n",
    "\n",
    "    # Clip values to ensure they fall within [0, 1] for valid image display\n",
    "    return np.clip(img, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a76e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, save_path_0, save_path_1, csv_path):\n",
    "    \"\"\"\n",
    "    Evaluates model accuracy on a dataset, saves predictions, and logs results to CSV.\n",
    "\n",
    "    This function processes a given DataLoader, performs inference using the provided model, saves predicted images in class-specific directories, and writes prediction confidence scores to a CSV file. It also returns prediction and label arrays for further evaluation.\n",
    "\n",
    "    Input:\n",
    "        loader : DataLoader containing the dataset to evaluate.\n",
    "        model : Trained model to use for prediction.\n",
    "        save_path_0 : Directory path where images predicted as class 0 ()'no_pneumo') will be saved.\n",
    "        save_path_1 : Directory path where images predicted as class 1 ('pneumo') will be saved.\n",
    "        csv_path : File path to the CSV file where prediction confidence (max probability) per image will be saved. Each row contains the filename and its associated max probability.\n",
    "\n",
    "    Output:\n",
    "        all_preds : Array of predicted class labels.\n",
    "        all_labels : Array of ground truth labels.\n",
    "        out : Array of maximum predicted probabilities (confidence scores).\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_path_0, exist_ok=True)\n",
    "    os.makedirs(save_path_1, exist_ok=True)\n",
    "\n",
    "    with open(csv_path, mode='w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([\"Filename\", \"Max_Val\"])  # Write header\n",
    "\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        model.eval()\n",
    "\n",
    "        # Determine the device used by the model\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        out = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, labels, filename in loader:\n",
    "                x = x.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(x)\n",
    "                outputs = torch.exp(output)  # Convert log-probs to probabilities\n",
    "                max_val, predictions = outputs.max(1)\n",
    "\n",
    "                num_correct += (predictions == labels).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "\n",
    "                # Save images and log predictions\n",
    "                for j in range(x.size(0)):\n",
    "                    imatge = x[j].cpu().numpy()\n",
    "                    imatge = denormalize(imatge, mean, std)\n",
    "                    imatge = np.transpose(imatge, (1, 2, 0))\n",
    "\n",
    "                    predicted_class = predictions[j].item()\n",
    "                    save_path = save_path_0 if predicted_class == 0 else save_path_1\n",
    "\n",
    "                    image_path = os.path.join(save_path, f\"{filename[j].split('.')[0]}_{max_val[j].item():.4f}.jpg\")\n",
    "                    plt.imsave(image_path, imatge)\n",
    "\n",
    "                    csv_writer.writerow([filename[j].split('.')[0], max_val[j].item()])\n",
    "\n",
    "                all_preds.append(predictions.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "                out.append(max_val.cpu().numpy())\n",
    "\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        out = np.concatenate(out)\n",
    "\n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}%')\n",
    "\n",
    "        return all_preds, all_labels, out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf030e99",
   "metadata": {},
   "source": [
    "MÃ¨triques d'avaluaciÃ³:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriu_de_confusio_i_classificacio_report(all_labels, all_preds):\n",
    "    \"\"\"\n",
    "    Displays and logs a confusion matrix and classification report using Weights & Biases.\n",
    "\n",
    "    This function computes the confusion matrix and classification report for binary classification (pneumonia detection), displays them using matplotlib, and logs both to Weights & Biases (wandb) for experiment tracking.\n",
    "\n",
    "    Input:\n",
    "        all_labels : Ground truth labels (0 or 1) for each prediction.\n",
    "        all_preds : Predicted labels (0 or 1) from the model.\n",
    "    \"\"\"\n",
    "\n",
    "    conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "    target_names = ['no_pneumo', 'pneumo']\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=target_names)\n",
    "    disp.plot()\n",
    "\n",
    "    clas_rep = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "    print(clas_rep)\n",
    "\n",
    "    wandb.log({\n",
    "        \"Classification report\": clas_rep,\n",
    "        \"Confusion matrix\": wandb.Image(disp.figure_)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4aef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilitats_sortides(out, all_preds):\n",
    "    \"\"\"\n",
    "    Plots and logs a histogram of predicted softmax probabilities for each class.\n",
    "\n",
    "    This function separates output probabilities by predicted class (0 or 1), creates a histogram comparing the distributions of softmax scores, and logs the result to Weights & Biases (wandb). It also displays the histogram locally.\n",
    "\n",
    "    Inputs:\n",
    "        out : Array of softmax probabilities (max values) for each prediction.\n",
    "        all_preds : Predicted class labels (0 or 1) corresponding to each probability in `out`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    outs_class_0 = out[all_preds == 0]  # Class 0: Pneumo\n",
    "    outs_class_1 = out[all_preds == 1]  # Class 1: No pneumo\n",
    "\n",
    "    plt.title('PREDICTED PROBABILITIES')\n",
    "    plt.hist(outs_class_0, bins=20, alpha=0.8, color='pink', label='Pneumo')\n",
    "    plt.hist(outs_class_1, bins=20, alpha=0.8, color='orange', label='No pneumo')\n",
    "    plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    plt.xlabel('Softmax Probabilities')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Save image to buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Convert buffer to numpy image\n",
    "    im = Image.open(buf)\n",
    "    im_np = np.array(im)\n",
    "\n",
    "    # Log to wandb\n",
    "    wandb.log({\"Probabilitats sortida\": wandb.Image(im_np)})\n",
    "\n",
    "    # Show locally\n",
    "    im.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c8351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corva_roc(all_labels, all_preds): \n",
    "    \"\"\"\n",
    "    Generates and logs a Receiver Operating Characteristic (ROC) curve based on true labels and predicted probabilities.\n",
    "\n",
    "    This function calculates the ROC curve and the Area Under the Curve (AUC) to evaluate the performance of a binary classifier. The ROC curve is plotted, saved to a buffer, converted to a NumPy image, logged to Weights & Biases (wandb), and then discarded.\n",
    "\n",
    "    Inputs:\n",
    "        all_labels : Ground truth binary labels (0 or 1).\n",
    "        all_preds : Predicted probabilities or confidence scores for the positive class.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_preds)\n",
    "    print(fpr)\n",
    "    print(tpr)\n",
    "\n",
    "    # Calculate AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Save image to buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close()  \n",
    "    buf.seek(0)\n",
    "\n",
    "    # Convert buffer to numpy image\n",
    "    im = Image.open(buf)\n",
    "    im_np = np.array(im)\n",
    "\n",
    "    # Log to wandb\n",
    "    wandb.log({\"ROC\": wandb.Image(im_np)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aee656",
   "metadata": {},
   "source": [
    "Save misclassified and good classified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misclassified(ground_truth_path, predicted_path, misclassified_path):\n",
    "    \"\"\"\n",
    "    Identifies and copies misclassified images from the ground truth folder to a designated output folder based on filenames present in the predicted folder.\n",
    "\n",
    "    This function assumes that the predicted images are named in the format 'filename_confidence.jpg', and attempts to match them with ground truth images using the base filename (excluding the confidence score and extension).\n",
    "\n",
    "    Input:\n",
    "        ground_truth_path : Path to the folder containing ground truth images (.png format).\n",
    "        predicted_path : Path to the folder containing predicted images with confidence scores in the filenames.\n",
    "        misclassified_path : Destination folder where matched (misclassified) ground truth images will be copied.\n",
    "    \"\"\"\n",
    "\n",
    "    # List all images in the ground truth folder\n",
    "    ground_truth_images = set(os.listdir(ground_truth_path))\n",
    "\n",
    "    # List all images in the predicted folder\n",
    "    predicted_images = set(os.listdir(predicted_path))\n",
    "\n",
    "    # Extract base names from predicted filenames (e.g., 'img123_0.85.jpg' â†’ 'img123.png')\n",
    "    predicted_base_names = {filename.rsplit('_', 1)[0] + '.png' for filename in predicted_images}\n",
    "\n",
    "    # Extract base names from ground truth filenames (e.g., 'img123.png' â†’ 'img123')\n",
    "    ground_truth_base_names = {os.path.splitext(filename)[0] for filename in ground_truth_images}\n",
    "\n",
    "    # Identify images present in both predicted and ground truth sets (potentially misclassified)\n",
    "    misclassified_images = ground_truth_images.intersection(predicted_base_names)\n",
    "    print(misclassified_images)\n",
    "\n",
    "    # Copy the matching ground truth images to the misclassified folder\n",
    "    for image in misclassified_images:\n",
    "        shutil.copy(os.path.join(ground_truth_path, image), os.path.join(misclassified_path, image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a424c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_misclassified_images(misclassified_ok_as_esq_path, misclassified_dreta_as_esq_path, save_path_0, save_path_1):\n",
    "    \"\"\"\n",
    "    Identifies and saves misclassified images into separate directories based on their confusion type.\n",
    "\n",
    "    This function uses the helper `find_misclassified` to compare predicted images against ground truth labels and organizes the misclassified results into dedicated folders for further inspection.\n",
    "\n",
    "    Input:\n",
    "        misclassified_ok_as_esq_path : Path where ground truth 'no_pneumo' images incorrectly predicted as 'pneumo' will be saved.\n",
    "        misclassified_dreta_as_esq_path : Path where ground truth 'pneumo' images incorrectly predicted as 'no_pneumo' will be saved.\n",
    "        save_path_0 : Path containing predicted 'no_pneumo' images.\n",
    "        save_path_1 : Path containing predicted 'pneumo' images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create directories to store the misclassified images\n",
    "    os.makedirs(misclassified_ok_as_esq_path, exist_ok=True)\n",
    "    os.makedirs(misclassified_dreta_as_esq_path, exist_ok=True)\n",
    "\n",
    "    # Misclassified: 'no_pneumo' (label 0) predicted as 'pneumo' (label 1)\n",
    "    find_misclassified(gth_0, save_path_1, misclassified_ok_as_esq_path)\n",
    "\n",
    "    # Misclassified: 'pneumo' (label 1) predicted as 'no_pneumo' (label 0)\n",
    "    find_misclassified(gth_1, save_path_0, misclassified_dreta_as_esq_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae4b37",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              patientId      x      y  width  height  Target  \\\n",
      "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0   \n",
      "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0   \n",
      "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0   \n",
      "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0   \n",
      "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1   \n",
      "\n",
      "                          class  age sex modality position  \\\n",
      "0  No Lung Opacity / Not Normal   51   F       CR       PA   \n",
      "1  No Lung Opacity / Not Normal   48   F       CR       PA   \n",
      "2  No Lung Opacity / Not Normal   19   M       CR       AP   \n",
      "3                        Normal   28   M       CR       PA   \n",
      "4                  Lung Opacity   32   F       CR       AP   \n",
      "\n",
      "                                           full_path  \n",
      "0                                                     \n",
      "1                                                     \n",
      "2  /home/nuria/rsna-pneumonia-challenge/dataset_t...  \n",
      "3                                                     \n",
      "4  /home/nuria/rsna-pneumonia-challenge/dataset_t...  \n",
      "                                             path_im  label\n",
      "0  /home/nuria/rsna-pneumonia-challenge/dataset_t...      0\n",
      "1  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "2  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "3  /home/nuria/rsna-pneumonia-challenge/dataset_t...      0\n",
      "4  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "                                             path_im  label\n",
      "0  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "1  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "2  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "3  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "4  /home/nuria/rsna-pneumonia-challenge/dataset_t...      1\n",
      "12269 3028\n",
      "9792 2381\n",
      "label\n",
      "0    6067\n",
      "1    3725\n",
      "Name: count, dtype: int64\n",
      "6067 3725\n",
      "1442 939\n",
      "label\n",
      "0    3725\n",
      "1    3725\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    939\n",
      "0    939\n",
      "Name: count, dtype: int64\n",
      "3725 3725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# DIRECTORIES #################\n",
    "## Images ##\n",
    "root_path = '/home/nuria/rsna-pneumonia-challenge/dataset_three_class/'\n",
    "train_pneumo_images = root_path + 'images/train'\n",
    "val_pneumo_images = root_path + 'images/val'\n",
    "## Csv ##\n",
    "#train_data = pd.read_csv('/home/bertam/CHALLENGE/train_data_PA.csv')\n",
    "#val_data = pd.read_csv('/home/bertam/CHALLENGE/val_data_PA.csv')\n",
    "## Ground truth ##\n",
    "gth_0= \"./ground_truth/no_pneumo\"\n",
    "gth_1 = \"./ground_truth/si_pneumo\"\n",
    "## Where we save classified images ##\n",
    "save_path_0= \"./appa_arreg_bofinal/classified_images/no_pneumo\"\n",
    "save_path_1= \"./appa_arreg_bofinal/classified_images/pneumo\"\n",
    "csv_path = \"./appa_arreg_bofinal/AP_nw_nls_cf_10_01.csv\"\n",
    "## Misclassified ##\n",
    "misclassified_no_as_pn = \"./appa_arreg_bofinal/misclassified/no_pneumo_as_pneumo\"\n",
    "misclassified_pn_as_no = \"./appa_arreg_bofinal/misclassified/pneumo_as_no_pneumo\"\n",
    "## Good classification ##\n",
    "good_classification_no_pneumo= \"./appa_arreg_bofinal/correct_class/no_pneumo\"\n",
    "good_classification_pneumo= \"./appa_arreg_bofinal/correct_class/pneumo\"\n",
    "\n",
    "\n",
    "image_data = pd.read_csv('/home/bertam/CHALLENGE/stage2_train_metadata.csv')\n",
    "# -----------------------------\n",
    "# Assign full image paths\n",
    "# -----------------------------\n",
    "image_data['full_path'] = ' '\n",
    "train_rows_pa, val_rows_pa = [], []\n",
    "train_rows_ap, val_rows_ap = [], []\n",
    "\n",
    "for idx, row in image_data.iterrows():\n",
    "    filename = row['patientId'] + '.png'\n",
    "    # I have to check if the image is in the train or val directory\n",
    "    train_image_path = os.path.join(train_pneumo_images, filename)\n",
    "    val_image_path = os.path.join(val_pneumo_images, filename)\n",
    "    # I check if the path exists\n",
    "    # I separate the images depending on their position \"AP\" or \"PA\"\n",
    "    if os.path.isfile(train_image_path):\n",
    "        if row['position']=='PA':\n",
    "            image_data.loc[idx,'full_path']= train_image_path\n",
    "            train_rows_pa.append({'path_im': train_image_path, 'label': row['Target']})\n",
    "        elif row['position']=='AP':\n",
    "            image_data.loc[idx,'full_path']= train_image_path\n",
    "            train_rows_ap.append({'path_im': train_image_path, 'label': row['Target']})\n",
    "    else:\n",
    "        if row['position']=='PA':\n",
    "            val_image_path= os.path.join(val_pneumo_images,p)\n",
    "            image_data.loc[idx,'full_path']= val_image_path\n",
    "            val_rows_pa.append({'path_im': val_image_path, 'label': row['Target']})\n",
    "        elif row['position']=='AP':\n",
    "            val_image_path= os.path.join(val_pneumo_images,p)\n",
    "            image_data.loc[idx,'full_path']= val_image_path\n",
    "            val_rows_ap.append({'path_im': val_image_path, 'label': row['Target']})\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_data_pa, train_data_ap = pd.DataFrame(train_rows_pa), pd.DataFrame(train_rows_ap)\n",
    "val_data_pa, val_data_ap = pd.DataFrame(val_rows_pa), pd.DataFrame(val_rows_ap)\n",
    "\n",
    "# Remove duplicates\n",
    "for df in [train_data_pa, train_data_ap, val_data_pa, val_data_ap]:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Downsample to balance classes\n",
    "# -----------------------------\n",
    "\n",
    "print(train_data_pa['label'].value_counts())\n",
    "print(val_data_pa['label'].value_counts())\n",
    "print(train_data_ap['label'].value_counts())\n",
    "print(val_data_ap['label'].value_counts())\n",
    "\n",
    "# Downsample AP data\n",
    "train_0_ap = train_data_ap[train_data_ap['label'] == 0]\n",
    "train_1_ap = train_data_ap[train_data_ap['label'] == 1]\n",
    "data_train_balanced_ap = pd.concat([\n",
    "    resample(train_0_ap, replace=False, n_samples=1084, random_state=42),\n",
    "    resample(train_1_ap, replace=False, n_samples=1084, random_state=42)\n",
    "])\n",
    "\n",
    "# Downsample PA data\n",
    "train_0_pa = train_data_pa[train_data_pa['label'] == 0]\n",
    "data_train_balanced_pa = pd.concat([\n",
    "    resample(train_0_pa, replace=False, n_samples=1084, random_state=42),\n",
    "    train_data_pa[train_data_pa['label'] == 1]\n",
    "])\n",
    "\n",
    "# Downsample validation data\n",
    "val_0_ap = val_data_ap[val_data_ap['label'] == 0]\n",
    "val_1_ap = val_data_ap[val_data_ap['label'] == 1]\n",
    "data_val_balanced_ap = pd.concat([\n",
    "    resample(val_0_ap, replace=False, n_samples=264, random_state=42),\n",
    "    resample(val_1_ap, replace=False, n_samples=264, random_state=42)\n",
    "])\n",
    "\n",
    "val_0_pa = val_data_pa[val_data_pa['label'] == 0]\n",
    "data_val_balanced_pa = pd.concat([\n",
    "    resample(val_0_pa, replace=False, n_samples=264, random_state=42),\n",
    "    val_data_pa[val_data_pa['label'] == 1]\n",
    "])\n",
    "\n",
    "# Final training and validation datasets\n",
    "train_data = pd.concat([data_train_balanced_ap, data_train_balanced_pa]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = pd.concat([data_val_balanced_ap, data_val_balanced_pa]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#Prove that we did it well\n",
    "print(val_data['label'].value_counts())\n",
    "print(train_data['label'].value_counts())\n",
    "\n",
    "# Split validation to get test set\n",
    "val_data, test_data = train_test_split(val_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset and Transforms\n",
    "# -----------------------------\n",
    "# Apply transforms to datasets\n",
    "train_trsf = CustomDataset(train_data, transformers['train_transforms'])\n",
    "val_trsf = CustomDataset(val_data, transformers['val_transforms'])\n",
    "test_trsf = CustomDataset(test_data, transformers['test_transforms'])\n",
    "\n",
    "# DataLoader setup\n",
    "categories = ['train', 'val', 'test']\n",
    "dset = {'train': train_trsf, 'val': val_trsf, 'test': test_trsf}\n",
    "dataloaders = {x: DataLoader(dset[x], batch_size=32, shuffle=True, num_workers=0) for x in categories}\n",
    "\n",
    "\n",
    "\n",
    "################# CREEM EL MODEL I HI CARREGEUEM ELS PESOS GUARDATS #########################\n",
    "# Calling the model and fit on training data:\n",
    "model = Model()\n",
    "state_dict = torch.load(\"./Best_weights/no_fer_Cas_PAAP_def.pth\")\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model_ft = model.model\n",
    "model_ft.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13732fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 690 / 939 with accuracy 73.48%\n"
     ]
    }
   ],
   "source": [
    "################ EVALUATION ##################\n",
    "all_preds, all_labels, out =check_accuracy(dataloaders['test'], model_ft, save_path_0, save_path_1, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628feb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no_pneumo       0.72      0.79      0.75       485\n",
      "      pneumo       0.75      0.68      0.71       454\n",
      "\n",
      "    accuracy                           0.73       939\n",
      "   macro avg       0.74      0.73      0.73       939\n",
      "weighted avg       0.74      0.73      0.73       939\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################ CONFUSION MATRIX ###############\n",
    "matriu_de_confusio_i_classificacio_report(all_labels,all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398f26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "############### OUTPUT PROBABILITIES ################\n",
    "probabilitats_sortides(out, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e33c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.21030928 1.        ]\n",
      "[0.         0.67621145 1.        ]\n"
     ]
    }
   ],
   "source": [
    "############### ROC CURVE #################\n",
    "corva_roc(all_labels, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e64982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'7fec8ddf-30d0-417e-b699-f75d862c7070.png', '58ad2808-fae9-4079-99b7-3f3eae239cac.png', 'e1215cb9-2d8d-4ade-846e-4328e7fa7006.png', 'a18358dc-b553-4fbd-bff4-33888b734eac.png', 'df09db89-b77f-424e-b9cc-6ba00dd047bd.png', 'da4d442b-bd4a-4703-9180-f437a5129444.png', 'e304f03c-1510-484e-afc0-aacec02c1b92.png', '43b42736-57c4-447d-9c50-19b92dcde9e3.png', '4f80b758-d33c-4e13-be26-55273d12c398.png', '73827f0b-0bc9-47eb-8249-14621ad77f5a.png', 'e5f292ae-f1e5-497c-b0a0-68f1aa2196b2.png', '10aa6a8e-4ece-4bde-b3d1-4406ee847cc2.png', '84a0590a-8a58-4a17-8e56-fa9229652d60.png', '1c2707d4-9385-4228-823c-51fb2a956646.png', 'f55de1b9-73f2-487c-b717-c09b047a388b.png', '865707e8-f2c1-47e8-a832-778ca4350c54.png', 'ec1aec71-ffe4-450d-bcf4-7b4fc52d31d5.png', '642da3d2-2da6-4973-9406-9d88c0f2f2c2.png', 'e08e0a02-10a5-4589-b17f-dc336d872155.png', '2626a2bb-234f-4309-aff4-317f6fac9b06.png', 'd6829280-5545-4b88-9cae-8b09ffe5b4cc.png', '15ec434a-959d-4e67-b1c2-2e9fa10b880a.png', '53b42127-3666-4397-9c0c-f2073dda27b9.png', '93f8e10c-5649-4f31-9dbf-b8e025e08cd1.png', '7ff721f6-5055-4d4b-bd48-e6d49e4d3e7d.png', '80ee782e-dd5c-4d8d-b030-6cb61322dd4a.png', 'deecb3e2-cd07-4076-8ef4-31df2afb4b53.png', '54c40643-1f30-49e0-ac48-2093df81d968.png', 'e855834a-56b1-473e-9d77-fa2ad603a42d.png', 'e6333801-dfd9-47a0-ba07-3911af849657.png', 'fe4f5b3e-c635-48b6-af5b-4b5d79283f3c.png', 'ef9fa526-2cc6-4950-af5c-11e9624fb611.png', 'e9674c4a-78a5-4af0-9aa6-f66d9a72c681.png', 'e6f88624-0bdb-40c3-9a36-7abe982a65c5.png', '648061f0-085c-4a9c-8efb-7d33b0a99684.png', '281d879b-1f4a-4ef9-a88a-c311d31415ab.png', '5c7f6d35-a4ab-4e95-bb92-9b82270f7ef4.png', '4fc32801-55fb-4b6a-9e1f-b61356d0c8ad.png', '659b4b06-6273-4efb-85fb-93e014d1ca2f.png', 'f7b557b1-623e-4466-a60b-ada96f7ba8ff.png', 'e9af92f0-49af-41d8-84ff-35f89293484f.png', 'fdca8fb0-7118-4143-b87d-cc42bb8b4f5a.png', '8545260c-9252-4308-9064-e954c8b8648c.png', 'fb4a8435-917c-4d52-94c6-9ed16c95a078.png', '0ccb9c63-16ca-4bc3-b2ac-b7fd85a845dd.png', 'e56c54cd-7486-4a34-9cad-eedaf07b0aaa.png', '68551263-19b2-4668-a694-f24f7be27ce0.png', '7bb16f3e-b843-49f4-bfa8-a9a9d6f3ff13.png', '74d35cd9-9847-4a97-a83a-22fc9eeb5dc0.png', 'e9b2cd1b-ae25-4bb3-90a1-a3a7208d1817.png', '5557ef6d-f13c-401a-9e2d-4d4800b3733f.png', 'dee545be-7a2e-45cb-8f4c-5edce22e2b00.png', 'b5f01025-fe74-4d81-b38f-44f6e64e7741.png', '606399ca-67b1-438f-91b3-de7d1914a7e8.png', '5adf75a4-81c5-4d9c-959b-6b9831babdd6.png', 'a729e14c-2d94-4ac2-a2e3-67f25e0818be.png', '768e5ccd-aab3-4971-8df8-814380ae77a8.png', 'e8921e9f-85d7-474c-a444-9fabbcda6e18.png', '7e44f22b-5f03-4fd8-bf9c-063a5ab6aa73.png', 'a4a9b807-7c05-49fc-bbe6-91807b980b16.png', '576c787c-993e-48ce-9a7b-9ee90661a0f4.png', '52e7bb63-d553-49cb-a27c-ea967b2daa52.png', 'a58cff2a-ad04-47aa-a93b-66091b5b584f.png', '1833d175-c9c8-40f3-9687-2a253e447579.png', '84c1ddab-f181-46c8-b111-b055ad42e6a5.png', 'cf49fc43-42dc-458c-99cd-6d20e717fe03.png', '53d56991-73ad-4f0c-bd6d-2eab1f84598e.png', 'caf25a63-fcee-4c61-9e04-71b3c401496c.png', '6c5538ff-1dfa-4543-9203-ec46c11ab786.png', '97ef09f8-293d-4051-84a4-52bc8401e0dc.png', '4e798168-140f-432a-97a2-60e44e7779c4.png', '677ffeed-5208-44d2-a43f-cbe64b7a5cc7.png', 'fe849ca6-4b1f-4a54-a807-3d0dc20a47ac.png', '8ecf57a1-3117-4baf-851b-9919d9873860.png', 'ccee99da-41c7-488c-920b-1628640e5165.png', 'a6b830fb-095b-42ad-a700-dd4d2a4241af.png', 'b394deaf-c6db-429d-864e-4f6aecc7a27a.png', '4c476833-0b39-4340-8fc6-c1be38cf13d2.png', '52877828-191b-4a63-b711-c65c1011c031.png', 'dc8a1d90-4ee9-4894-a68c-84a2f06dcb34.png', 'e58809d8-f9ca-4dd1-ae64-c175c4c468a1.png', '503fa416-d6bf-4cc3-b876-13210dc070c8.png', 'f6d5b202-5ff1-428a-8d3e-5b64d67fc095.png', 'b6f8ef19-5d1c-4b9c-8c3a-e9afbf1f863c.png', '68afbac1-86dc-4ff1-be69-f936a9dfe342.png', '75431238-8d46-4b70-bbb7-128bd58602cd.png', 'e3f6c8b4-6647-4a84-aa33-50d06297be03.png', 'c82bfff3-fa30-4141-b074-5e3ee9cbdc2a.png', '56c7ab59-2418-4b3a-acbe-c7b3dfa51be8.png', '6dc8af39-9d3e-4f4d-8614-2eb672b6e554.png', 'f4f59f5a-2958-43fb-89c4-2f97da2cc0f2.png', '7f57a568-9ec8-40eb-9762-ce5831ba29c9.png', '4a6f5410-4668-4cf8-9628-5b09dd40c527.png', '9a80d9b0-c59e-435b-9b65-6cb88d457a6b.png', '45e249f3-bcfb-4a4a-af37-8252b32e8f8f.png', 'deaa3ba8-186b-4aad-8039-506f7939222b.png', '61daa6f5-8963-4579-8318-3fefe34eb85a.png', '51da5ec9-42d2-4d2e-aeb2-be7104a367ba.png', '7828fb21-d2e7-4bbb-b874-2c7b73e1e8fa.png', '6b070b27-6f76-4432-96fd-0ff8b32f89d9.png', '9299cf6f-bd4a-4dc9-90d5-893e770566fb.png', 'e62248f7-b69b-4ae9-830e-57fe279af4b1.png'}\n",
      "{'21909788-6009-48a7-80c2-8ee149b18251.png', 'e178c7c6-a213-4023-a125-45cf59949b20.png', 'af8a9a3f-9487-454b-8ee6-65c9554f3a87.png', '7ae2ae8d-3370-4e6a-b1db-8ab3ac862ce3.png', 'b5046b7c-f721-4c19-b3ae-51f095f36fe6.png', '254d15d9-dfc5-42a2-b2d6-f208527d6396.png', 'b54c5581-bb40-4c19-9d5a-3be944ef8132.png', '17398977-1b0f-4de4-9038-9c8cb7406c82.png', 'b8fd583c-2159-494a-bed3-88a3c0370efa.png', '73d61528-0457-4796-9ccf-6d23f76bdd73.png', 'b5022e52-4742-4b8c-b432-487fd9a9dbfe.png', 'a332b7c6-2db8-4158-a01b-ab2baff58cdc.png', '83a7cf6f-434d-487a-b273-5185ab1b2f24.png', '345d1a85-8d32-4e43-8e9f-dfb0048da3fe.png', '3606dcdc-56a2-405f-b799-2f7e13d1b2e8.png', 'b51c3c24-f9aa-4039-9fc1-527a5567dff6.png', 'd77b519d-abb7-49d7-8bec-dedebe8f50d1.png', 'f9c4f02b-52b5-4f36-96d7-b706d678d9b9.png', 'afa1bff5-3158-4bd5-bfe4-e85bcd3577d7.png', '3496cccd-1600-4ae9-920f-a5bf7919801c.png', '8a7d2eff-9c77-461e-b50b-b6dac8e54ba7.png', '8da6abd4-8940-4696-bc43-6f0891cb7493.png', 'bd164f7a-a3a5-40d0-933c-0d623be3ad94.png', '3c4c732b-8281-41ef-bd8c-98f98a1c11fe.png', 'ab4e14e3-259f-4e54-8860-b2762e8374e9.png', '9c3ec0a7-6816-46e0-b797-8412bacea535.png', '25c915e6-1b94-43b5-a19f-21931faac3b2.png', '36ab4430-59ea-442a-9968-9329b3c93954.png', 'b73735b9-8b15-4def-9131-891baa6f64a9.png', 'b5a4e967-a8dc-40b1-88dd-a6685fdc26eb.png', '46da5af2-a757-4670-90cb-5cc59c1e6d87.png', '9e43a65f-f310-4cb0-a645-8ea52d98f88f.png', 'a8031125-1a13-40fd-9aeb-164e1a421f22.png', '11c4dd33-9f7a-4b01-804e-051ab0d0e3e6.png', 'ffae40ab-fcfe-4311-a74a-89f605dba48b.png', '0c248828-72e2-43cf-8622-b5775c421fb1.png', '90be7b6e-0db5-4395-843e-d38966f41412.png', 'ad463d4a-996c-4f96-90ad-1bb3594e5a90.png', 'dcca67c4-14b9-483e-bb8d-adbcbb767533.png', '3c66e4d3-1167-4322-8367-b50e762c138b.png', '8489c930-19a8-4895-9211-4efd3d38ae58.png', 'e7aed9f9-264a-40a3-84ab-1ed8b81547df.png', 'b77ab795-de76-4715-b371-eb7be54b584c.png', '664cb381-ccdf-4c19-8a86-a664d402221c.png', 'b0047aab-84f1-44b7-b485-37df40388101.png', '3333d928-dd10-46f2-927e-f7d5ac070221.png', 'b78a4ada-0963-4067-a009-3f8ee134e069.png', 'b623e856-e328-4396-a01c-4d6210c2dd53.png', 'cbbd4c12-de6e-4bf4-b782-0b46ca63d645.png', 'ab93d6fb-751b-4eb9-a022-9affc62846ed.png', 'b8cda939-dfb4-455b-9ff4-17e199b3ad1f.png', 'f12565af-43de-4bc9-9dba-a8a3e9c8331e.png', 'c4528f64-a6a4-4a65-bf14-1f234871cf30.png', 'b7b1abfd-c7e8-4404-aeed-b3a3b489443f.png', '8a9eb130-2d16-4a85-9f57-c8795d068f01.png', '3ae1c3de-e2a7-44f5-b794-b1ef71640d0f.png', 'b1cd1f20-1ea8-4520-8875-97fa8c83dd9f.png', '514fbabf-3986-421f-81dd-fa99d8040082.png', '03a9498c-549d-4e7d-800b-e74797f7f625.png', '1a2dc891-713d-4253-ad19-a1e7910ee2eb.png', '73212dc5-6535-4837-838b-f08aff61c1a3.png', '55891cc7-b8ed-4b22-8bf0-a6039dc53727.png', '1748e4e2-5c73-4794-81fe-2c5fe4af8cdd.png', 'f26f795e-e989-40ce-a076-5763295ce46b.png', 'ee820aa5-4804-4984-97b3-f0a71d69702f.png', 'a458d820-3a26-4f46-ab7b-28f42a1ff4e0.png', '31ec89aa-09c7-4342-8bb5-ba7b585e875e.png', '2f873371-c1a7-4c07-9470-3bbcc201832d.png', '34d37f0b-6aeb-4af0-b0cf-f4516a3035af.png', 'bddd048f-116f-467e-803f-fd234c53a61f.png', 'f7b45870-76fe-42f3-9833-acef8c336dac.png', '3fdcd01b-1029-40c9-be8a-a72876d0323b.png', 'aceadc8e-a025-4184-af7c-20325cb516a3.png', 'ba66a843-4afd-473a-82a6-7cc80bb74757.png', '18b5d52d-78e4-490a-a766-af881acda223.png', 'a3bcdd23-510f-4f18-876e-69bc9cf62ada.png', '0a7162ad-b2bc-4132-b15a-7fdc80957618.png', '1a2b6a01-88f6-4907-adef-f396a00a15b4.png', '06bf9151-5732-4968-b198-f4109676cd55.png', 'bae7b652-311f-4a84-a031-653424887f35.png', '768e5d7f-10c8-45c3-98e1-7487f808a42d.png', 'a195a887-4e7e-44d9-b9d0-a2a72b1c243c.png', '3bba8ae0-61b8-4682-8b16-2e08078878b9.png', '8a61a6c6-b600-4eb4-9bec-ea32804c03b2.png', 'ae50eb15-92f5-4a90-912c-20a8cc745be0.png', '17c749dc-e97a-4c5c-b4f4-c68b135a1a64.png', '34aca5a7-7786-4060-afea-cf31d8fc05d6.png', '57880594-01e6-4768-bd1c-b943840d6040.png', '69220eb7-f35f-4620-9a62-cd5478fc9f99.png', '293f4b7b-3a6e-44a6-b9d2-810b139094cf.png', 'd561ede1-9992-4d20-a935-53a32a8c05d1.png', '19b43d5f-840f-4eb7-b34d-e36868ee7af8.png', '3b17bfb9-8657-4b74-bae8-f597877f4227.png', '3ea07f33-3cd8-4a27-b680-8e1bc57aa1b8.png', 'a30808af-7822-4f47-beaf-0c1a840cd980.png', '388cc388-c2aa-4bfe-8a63-4565c626d951.png', '13fce2c5-6834-485f-8280-c3b0c1b952b5.png', '28ba0617-0cac-4198-8b8a-c35fde545ace.png', '3d8a52f8-3769-48d7-9460-2df223a06632.png', 'f23d7784-06b4-4e44-8dcd-e1eec3e7d7cf.png', 'f78a62d0-f9aa-4828-ad8c-ec4917f52d48.png', '05dad446-45f7-44df-bd2f-4673d9502348.png', '36c3ea72-267d-4eb7-a0b2-a3e34acd2d07.png', 'bedb1f67-9f34-417b-aa14-ebfca18a38b5.png', 'd73404b9-b882-4d8f-a14f-876aa52c9559.png', 'b47d39df-6c53-4b24-8f63-6577deb5e798.png', '47b6aa0b-bd34-42a0-a0ad-469a1c6e3e1e.png', 'ae094b72-b7e5-4dff-a775-8bab37b0082e.png', '32ec2e2d-9efb-4510-a7c1-14a007336a68.png', '3c072590-e9e8-4ac2-b9e7-dd1776e2a537.png', '2d6d00a6-a1e4-4423-879c-3fb846daa88c.png', 'af59f4a2-32d4-4888-ac7f-fc0bcc23abd2.png', 'b07a3786-2c97-4204-8fa3-4b303d4d655f.png', '62e7f210-65e0-40e1-ba52-8c21b6e767e9.png', '059f1e59-573c-49d1-ac78-3323a2ff047f.png', 'ec8965a5-1774-4644-8e58-dd62eacc160e.png', '097788d4-cb88-4457-8e71-0ca7a3da2216.png', '998e3a78-6d50-43e2-af5c-56a1b747092b.png', 'f31a958a-66bf-4ccc-9fd7-79bbb9d17e7a.png', 'b396e6cc-f447-49bd-9b86-c75c778f1e35.png', '3e4ee273-d5ca-4cf8-a75a-05772e0e12fe.png', 'e15ecf55-b05a-4f6f-bb25-d51d4a438963.png', '39d6260d-397c-46cc-bdac-c8e908a91f6e.png', 'ae794223-db3f-4b8d-a307-a5cb1ac5eb57.png', 'c27d0e06-ef8c-44ca-b4cc-a4113b723570.png', '8375d80e-2122-4b60-811d-0da040f6b68e.png', '38ead95b-c698-4cef-bec8-3f95005484c3.png', '9b176562-4004-4e23-965f-ae050251378b.png', '3b3d0da3-cfb5-42c8-a195-6ac03626a11f.png', 'c33b5552-ff51-43d5-bcee-9bad9c372de6.png', '391ea361-3ebe-4930-9645-e14740e6d58b.png', '5ea7521b-b287-4ddd-ac55-14e05c75d62e.png', '12fb963d-f74d-4c83-a3d9-c96ee8983ff4.png', '133a1f56-1ab0-4df7-8e1b-4a6293934f3a.png', 'ba278d92-c5ff-44f4-b1b8-7d3454df7e54.png', '3c993fea-80ff-42d5-a7ef-e2fb8209e4cf.png', 'b8397df9-1bd5-4961-b756-978ff4aed6cf.png', 'b17fc3e8-99ee-4297-8432-0bbef7d24e1b.png', 'bdb79995-00a2-4b13-bfc7-6f06f8639498.png', '01adfd2f-7bc7-4cef-ab68-a0992752b620.png', '0f45a78f-d20b-4370-b0c9-00da4e9a8a05.png', '049d7317-5a8b-4fc4-b81f-159fe6b45a92.png', '0adcbadd-6b95-4692-bdfb-6a03d51af237.png', 'bb7973b1-58b1-4e2e-b687-144e179f0996.png', '784aa072-7400-4f08-869c-7d47230d198d.png', 'a23ac27d-83b3-48b7-837a-dbbe83752ce3.png', '3f167edb-74e4-4a4a-b710-9732659ac767.png'}\n",
      "{'6f50bef2-f849-42c1-8e00-d3003b9ced67.png', '3a90e0ef-db94-463a-a74d-f0f3a12788fa.png', 'e7038aef-3a42-4a0c-8de6-8e7a3c903e48.png', '63fb7926-b7b4-4bbd-b47f-5aad34846ad0.png', '799c13e6-dff4-4c52-9aaf-b9ea6daeacb1.png', '6ed0c46e-ad1d-4fd8-87c7-cad314fb177e.png', '71d99089-75f8-42d3-9216-33b902503e6b.png', '47a4611b-39a7-4d5f-947b-33024366d632.png', '3c1a0a47-72ef-44df-bc99-88af8a191c4d.png', 'eb80a466-3ba1-44cc-8896-e150604a2b54.png', 'f47b9425-6f76-404c-b15b-4efcdbc66a56.png', '91a4c9e5-1800-42ca-87d1-6762cd65bf51.png', '5dbb4c6d-0f62-48c7-ac40-4eca9562a74d.png', '7ae0a78d-464e-4d3d-b1f7-123bba695bc4.png', '7dd2a36e-d9f5-4152-ba5a-17ef5777a7ef.png', '9c6978ae-d8f5-4f39-8162-d6d5b105f3d9.png', 'babdbcc1-8748-482f-b646-8034334fec25.png', 'ef6ccb09-61d9-4eba-90e6-0f35fdc02266.png', 'd59a852e-d15a-421d-a887-2d371cb5d96f.png', 'ed3a7a17-baad-43fa-9083-60dbe189074a.png', '8f24585e-1f1e-439b-85b2-e1326f99de8c.png', '6a9107b3-b846-48bd-878c-fb547c8bba7a.png', '68111058-0da7-4406-99f1-fb316fef9c10.png', '173e6c82-aa90-443c-8cae-9e284713ca7c.png', '9bdd01cd-079b-4790-8854-494047a4dc06.png', '1483c479-9496-47e1-bfd2-bda652f83fc9.png', 'c6f1d032-6dcf-4ff6-a949-884b0416d7a0.png', 'ce6329e9-f7d9-4212-b6b0-22150330c6c4.png', '5cb55af6-404c-4a17-bfa7-2007465407b4.png', 'a4648b6c-713a-4c72-a126-1115ec122e27.png', '2bd138cb-a07a-48b9-bbc9-137a460e1e2d.png', 'e57c446d-fc83-421e-825a-3f917a6a6565.png', 'e2c633e0-f476-47c4-b178-250907fd9a0f.png', 'fe169755-e3b1-475b-a31c-e273c77b2013.png', '1f6e80da-8d59-439d-a711-9d72e5195805.png', '55abf5e9-a924-4ac1-b397-d5404b421b79.png', '7471b2a3-12dd-48dd-a43c-04c4718e5e20.png', '81d44b9a-f027-48fc-9dd5-5c132dee416b.png', '85dad6b6-8a4f-4189-b1c0-006a66f5b0bd.png', 'b588dce0-b8ce-4a96-8b3e-f3f31d229467.png', '7907faad-9e9f-4690-bf76-420ff9b64f7e.png', '000924cf-0f8d-42bd-9158-1af53881a557.png', '3e1b619a-cdd9-495a-bcbf-a9d62b418991.png', 'fdec46aa-eb1a-423b-ae4a-b78af0bb9ece.png', 'e435782d-cda4-4960-b3c1-684611e74e60.png', '458d66fd-5dab-435d-b937-3e19e5302145.png', '39020ca4-0e5d-4b53-899d-fe72699cdfc3.png', 'd2fb0399-7c28-4d9f-9ce7-64e7c4570315.png', '71b0ce4b-d1dc-4e08-9e22-be77adec71c1.png', '9dda6b23-67f7-43c2-90db-aafdcd057042.png', 'ad161e98-3d85-4e8a-816b-ea0f2fff4612.png', 'd459c288-923c-4e28-b887-52a0af807d27.png', '355ca2f6-2947-4f1f-9d21-a876bd6df049.png', '7c328c0b-3a48-4043-aa50-d592e59fbf96.png', '855262ba-9cf0-4b86-bae5-c7034b457d7e.png', 'd2dad359-4912-496d-94d4-128d2d5942f1.png', '73114e87-0b3b-48bd-9c9d-94c92c488997.png', 'fe4c6320-e70a-4ba0-8e2a-d51c5c29d8c2.png', '108a989d-bd99-4e96-8ce6-ab21ffd0d79f.png', '6904e6b8-ec78-40bd-9e20-4d13f53c36e1.png', '94e5ea07-818c-4d2d-bf2b-022ddd979be3.png', '5a29bf0b-e88c-4c2a-a793-6a84c9cb9856.png', '7b433c27-746c-4968-b958-397f1e81e36c.png', 'c48ad889-3b33-4b06-9b38-4feacc87a830.png', 'a2b13cd7-501a-400c-ba0a-533419bbd03f.png', '3b0df968-c8e2-4c0d-8401-f42b104850a2.png', 'e294484c-a1f2-4011-a62c-69b303b0895f.png', '5f6f8f25-1b29-43da-9ac8-01970feb489c.png', '7f3d7c10-5774-4d6b-8fab-5e41c42d7665.png', '5382542a-4669-4044-bd7a-9ff2dad7db6b.png', 'fd070065-c0c6-466e-8743-c440da108917.png', '4766883c-4a81-4419-855e-5ed5c4142da0.png', 'fc4cd513-fc64-44be-aa46-83515c121eee.png', '6a564802-a75c-4a40-957b-110303263bf7.png', '6dc64ab6-caca-4a31-bf68-7fb5955a3f0e.png', '4823a67b-3f20-4d8e-a7c3-7d3226316b87.png', 'c4ab6f36-9b8e-4302-991b-07eb251a9c10.png', 'd1d10f54-3d47-4c60-aae2-dfd0f92e0b4a.png', 'b9620b3d-96be-46bc-ae31-8d5d6d8491f6.png', '07290e87-0c95-4daf-ae97-2f7f971f23c0.png', 'b2db97fe-2ad5-48d9-800a-b909a36e7158.png', '44a6ee95-56fe-4a68-93d7-c5f046bfcb40.png', 'e66a0926-62c9-43f7-9853-3ccadb9fd630.png', '54cbe63c-5c44-4d55-ae01-0096c805dda1.png', '9c23a9cf-35dc-447e-bdbc-dc85a32f05e4.png', 'f4bad3fc-bc93-4634-bed9-a9977f6cec56.png', '4d246f03-3d83-45e3-aba6-80edecc444db.png', 'ed676702-5612-4ffc-96a4-8d1e1cbd32b1.png', 'ef2f4955-9209-4d8f-8a36-f668b85df90a.png', '6dd00cdb-6ce8-407c-906d-322688b78a4b.png', '9da5f69a-7024-41e9-bb8c-ecd617f3c06a.png', 'dd922253-21a0-40df-8e03-febb6dc20d2e.png', '45e259c3-c0e8-4d00-a6c8-f976328372ea.png', '0b18dcfc-c526-435b-aea8-d8038aa224ef.png', '81e1e4c7-34f3-4c0b-be39-1066ad72e18f.png', '772360c5-7c53-465b-b04d-3c8646fa3a23.png', '2f678d71-59cc-4acc-b2a5-673c25d578e9.png', '9f8676ed-ec75-42d4-bb4d-304fcaace16d.png', 'bf60b3fd-3040-4a61-a009-37ce6bc19976.png', '8d67aafc-e87c-4ddf-a431-8edd9fe99b44.png', 'a2ad563b-6e82-4724-9016-e4033be97e4a.png', 'd5f2f97c-394b-4bb2-aada-5d58419f7a33.png', 'd2515465-fed3-4795-80fe-cd24021259da.png', '4e191f85-f6fe-4c5f-89a4-c22a2c3db807.png', '462660b4-7813-4a43-93ea-e889f69f9c2e.png', 'cc1207ca-a01b-4fb2-8b1b-4341329a4d25.png', 'f71656b8-8746-4025-a813-9ae4c61a0d36.png', 'eec5fd7f-f418-4071-8a30-60e16a11d9a4.png', '958f4388-559f-482c-9b7f-33eb9d64ea61.png', 'a1a9bf98-fc6f-4678-a621-12abfb777542.png', 'd6b6027b-bf05-4ca7-a1d6-8b8bf40cf76e.png', '2b75b5f9-285f-4e51-aed4-26e08811ff8a.png', 'bb59562b-cfe1-416f-89cd-f2e4e048d107.png', '758dac04-0896-4df8-8b96-dc14c42ea547.png', '7066078d-0568-4411-b20a-09d0c9a87ffd.png', '09e8fae9-1714-4b54-a1d3-42a29a9717c3.png', 'ffc9e552-ca53-43a8-a156-b0f97f0d40f3.png', '8000975e-2a81-43b9-8c72-ba5eba37e84e.png', '5f46ec60-1942-423a-9a58-1856218d94d8.png', '95843297-b9d3-43c4-95a5-c993f97f1b0f.png', '33eda96d-5906-4dfb-8633-ada51ada1e9e.png', '5fa8b1d1-27eb-4a5a-9c83-b144e9962424.png', 'd7782dea-1200-41a6-9281-c5daf932b652.png', 'b9209ba8-6f25-4805-97ce-e1ed39c4ab71.png', '44c8b746-13a7-4245-a82a-b61d8b5ba562.png', '7e299a8b-364b-4348-bd16-c43ece7c9d12.png', '89d63d9c-91be-49b1-a072-a4076a35a29b.png', '8c62b364-84be-4c83-9c3a-43df335a1978.png', 'fb4e8f36-76ed-4354-9b37-545743fb3ca6.png', 'dcb75f58-6982-49d5-9a12-75ea9c632d56.png', 'c87428e8-09b6-4b65-8a28-137c147f3e80.png', 'a098e79c-1708-4941-ab66-be1c58aa1a61.png', 'd17e08fa-cd21-4bd4-b3d9-3b55d51ee9cd.png', '281a132a-55d5-49de-89a2-34fdfbecddeb.png', 'e14f7f94-baf7-4dea-b3e6-d69b29576e3d.png', 'eec7d0df-d857-4ad4-aebf-95042462b87d.png', 'd5e25174-e2eb-4a71-963b-24adc75fa6c7.png', '48e7d8e1-f4a6-48e5-98dd-d96e5b3ccd79.png', '0889b108-8f03-4fef-9ef3-5ddabde15ce7.png', 'c4a2f14a-82dc-49fc-aa03-037bf6b99c6c.png', '53931ba8-38aa-4407-8de7-ba36e0d065e5.png', 'b1d545f0-8658-4533-959f-dc32955904ca.png', '9888cc71-4d0d-46be-872d-67150fe65ca9.png', '6f09eb03-cfb5-4936-919e-e08cb3b9555d.png', 'cd57c200-4f4d-4678-82ff-0af8bad6b862.png', 'd086792f-5d97-473c-b0f3-291385da233f.png', '90586c17-d239-44f8-b9e5-3d56506ac034.png', '986b7d41-c4b8-4a03-8832-bb4cce856de3.png', 'c8281919-a362-4019-950d-86ab101c7e1f.png', 'de593794-d905-42b7-82b7-459f567a2672.png', '992f14c2-8e2c-4341-a257-4186208e716f.png', '7f855bcb-ce9f-4458-80f5-f613cf9b71a0.png', '17f54918-66ce-491f-b674-97c2e365f1ef.png', '377e27f0-1fd5-4cc3-93df-6c491ef2d755.png', 'c75f315e-ca15-4d67-9068-ca2d9fda95ab.png', 'fd46ed8c-00eb-41f6-b3da-e11b3e4982e7.png', '277b4a9d-7987-4da4-b421-1d1450fc1266.png', '187d657f-6de2-41de-bc6e-0bed9757aade.png', 'c1e3eb82-c55a-471f-a57f-fe1a823469da.png', '9c0030d8-fa33-4df1-be81-23ede246b0a7.png', 'e7ece924-978e-4d9b-aa51-880dbe26f155.png', 'c568ef01-6904-45ec-990e-2986a961dd00.png', '7c6d38a6-bbc3-4dd5-b4ad-bc8a7758eeaf.png', '7bec73d2-1a5c-462a-b9d1-29e4b5ee6ab0.png', '3fc13fa7-0981-4dae-8d4d-ff8769f98d28.png', 'f3826a5e-d3ca-41c5-b389-c128589aacd1.png', 'b87e3b2e-d7a1-4b29-86eb-0c08b1d3022a.png', 'a0e4d764-537c-4dcb-a976-d15c6abd87ce.png', 'cc02cb11-03bf-455f-bbf9-a75b66c28127.png', 'f87cf3dd-a96e-46fd-b777-f5bc480a2de1.png', 'c6612ebf-ecfb-48ca-b274-e60813aa2c7b.png', '562262f4-c462-437f-9a5a-29034cc5961d.png', 'cccd0a53-db75-4d87-bf5c-d6e41ee41bb2.png', '2458bc6a-a46c-42f7-b25f-135c7db35a8b.png', 'b71f4358-f597-4193-a80c-ce223f708bf1.png', '0f4b80b6-fd39-451f-aebf-7cdb1b655c0b.png', 'ee84aeca-9b5f-460e-af58-3ce02d9b601f.png', '76f54014-f16f-4010-8f53-4a9237281615.png', '7d5c6cc4-1ef4-4f84-ab53-f736f4844c3d.png', 'd49bcf22-7409-4f93-b1b1-54306042f5be.png', 'accfe124-5be8-42e4-86fb-630ad1f11c73.png', 'bace143d-57f3-4514-8fc2-a69a9e7e11e0.png', '938d2c83-61c9-49a7-b031-807ea7457836.png', '55a675f5-001b-475c-8abd-141e86021b4e.png', '571d877a-4c56-4400-90ba-8fbda622daf2.png', '0324368b-3c2f-464a-8b1a-f72113718c38.png', '623ec44c-890d-4ef1-8fa1-33c0ef771df9.png', 'b2f114bd-c0cf-4c98-a929-ac5add3103b7.png', 'f6763491-eff0-40fd-bb34-f61e0b0da4ae.png', '44fb08f1-0718-4dbf-b42e-b44fd500ebd5.png', '02c2331d-b3fa-4d55-bf86-f0efbd589c86.png', 'e6d05f66-9b18-48e7-8756-c03e81066405.png', 'de1a09bf-91ec-445d-b9ac-ad5aa8d040bd.png', '297d1d92-8116-4bfa-970a-9bddf591f1c2.png', '7d889abc-6804-4b28-adb3-3540ecb055c6.png', 'b6eb4991-000f-43e9-bf39-2ffd63fbedb1.png', '3428d5f3-ae3f-43d1-9f7a-9d7d4afd5782.png', '3197fa6d-696b-4f85-905d-77b825d89a9a.png', '74192b5f-7e82-4636-9886-c2c1750d833a.png', '7ea6a920-a1ad-4cf1-91d5-a6634708b12c.png', 'eb632397-ff01-45ba-9bb7-23d1d376821b.png', 'a61b96d1-418a-4841-a26c-0f2ad9e9f1f2.png', '40eaca23-ac68-4025-98d5-f62100c04350.png', '5460b0c1-6e89-40e7-adc0-c75dbe7c9e09.png', 'd719e1fe-366a-4d2b-a816-f0f1bcf3e4f2.png', '05c4f636-2c27-4b78-b874-878f499813aa.png', '72980284-41de-4a91-b722-ab180bdbba7e.png', 'cfa337eb-7ee0-4013-ab0e-c51376cc9b5f.png', '35cda03a-0898-4f8b-92d3-6f263aed23ff.png', '5bd84e26-fe41-4661-8fe6-d443473e4914.png', '1552da4f-04de-4c70-8c82-b5e3b8012b93.png', '1678b850-2b76-4d6c-8f8f-bf1503e2d761.png', '3c2e061f-ad8f-497b-a97f-196d2606ffeb.png', 'e56fe4ee-79d2-4627-ab35-d209e197440b.png', '582137b4-6d8f-4933-b461-2cb08a7187c6.png', '5828e978-162a-4726-82e3-a057474d6b8a.png', '5a9947e6-bd14-440b-ba5a-09d52b1b4c68.png', '369fef8a-d290-4b0f-a4cf-02b2690bb9b0.png', '782101a4-b13d-4fed-9820-08374c8b896b.png', 'fa9acd74-3b4a-42a4-9726-fae933108fe8.png', 'c6538cef-9563-40fa-bafa-46697e5259fc.png', '44ec9790-ae4a-4a9d-ae70-36fef1cefbfc.png', '4affc9f8-39a1-4c8e-925d-890658b67021.png', 'f1efd5e0-c6d5-4d98-82cf-af28ef0ad044.png', '7f20b8b6-47ac-4a81-81d4-77824b0b69f5.png', '454b98c1-3a2d-49a1-bfd3-8e43c3c1ce55.png', 'a2572ca9-37e1-4558-b260-17a877ce78e5.png', '83fa7e9b-cdfa-499d-88cc-278de00fbbbf.png', '9ef59ad6-9d71-4b08-831e-b77436550ba0.png', '1912d25f-9584-4143-bd72-0766609e7585.png', '6607a20b-41cc-4215-b502-370929cb459f.png', 'dd89f00f-0724-4a79-a766-3926a421f9d8.png', '5d15bb3c-8eea-4894-b5a1-6bd75c171f04.png', '51d905bb-48ae-4d6a-a69d-5a2aea153f59.png', '9029af01-d95a-4061-bf2e-dc24e85b734a.png', 'b208b6b8-807a-4325-8bb2-790e2e705ec6.png', '08b9ee23-ff64-4494-b293-5e43f3de3453.png', 'ce808df9-fa39-497f-a393-efd4890474a4.png', 'de2ab5e7-5cdc-443e-9905-f4469d98f8b1.png', '68c13574-a0dc-49e3-8004-923f0b2d278f.png', '7d60aa42-943e-43d4-bfa6-d06fcb22d7b8.png', 'fa8ecb83-87ca-4c08-bc50-3a020f8a76f5.png', 'e6d18207-9599-49b6-b535-d6d1d77815e6.png', '754ad4f4-7de6-43d5-9553-a58ed87532b5.png', '96db28af-42ce-4b34-9ac4-e33cfa7a1706.png', 'c6b23bea-5014-4fa0-8bfd-3fc5c91733b3.png', '4978d51b-8093-40ac-b4e4-11aeab1afe09.png', '74be60d1-0885-4010-895d-297ea831ddb4.png', '2098cb66-63ff-44e0-b741-c8e84199d7b2.png', '4ad69283-4761-4acf-94bd-6d7c482b28d9.png', 'd1d9bf55-e999-4e44-be02-aa94b7ab0e77.png', 'b5de935d-902c-441d-bf47-cde979d6f9eb.png', 'f37885af-d611-402f-a662-7e9d6deb5bbb.png', '9addd7f0-dd54-47db-b70e-bc9baffe2b14.png', 'eafa1f43-8b67-485c-9f1f-5981ff4154f3.png', 'ef7d7b4d-ebb8-4975-bc3b-4a053b12699a.png', '4ae71afd-6dd2-436b-a14c-b7484e3afbfe.png', 'f07012f0-57e8-4d02-951f-087ae7c8ce5c.png', '8b46540d-e0b0-4c5c-a5d2-44af5da1bf2e.png', '9ea62a2d-578b-4945-8d7b-d2f8d7773b5e.png', 'd69499a0-85e2-4dd6-814a-80ae86d3dddc.png', 'efcddc12-4d79-4245-84e5-ebe3ac185e7a.png', '5b7a9d09-53e4-4584-a1a1-38e594d091e6.png', 'abe39f96-f9ee-4539-a408-c7a623c4d778.png', '8af55420-a4fc-4443-90e4-becf53817b61.png', 'e4dce044-ebd8-4b56-bed0-e7ba7f837927.png', 'd60394b5-1f55-4929-a054-abd1eaa5d088.png', '58b27c0b-8635-4c71-9c4b-babe51801da4.png', '63bf1710-792f-46ca-b50b-932e501b0402.png', 'def7067b-e6c2-40ce-8c08-1435e04fe14b.png', '83fdefc4-082e-409d-80dd-7b043aed85ad.png', '5ef82d3e-536f-4334-b0e3-81c03520ec1b.png', 'e5668b84-ad6f-4647-9e15-c15a5cf41c97.png', 'b25d0f5e-c2c7-499b-a3d2-65b1f71b9d30.png', 'e2ad3d7c-e284-46df-ad80-b6d04dfda188.png', '575c312c-82f3-406b-8945-2b37da0364ae.png', 'ace00a2e-5c0c-48ae-8b67-651f742f6820.png', '485f1ddc-8562-432a-a27e-9c54375c19ac.png', 'c51dc029-0ac3-44b7-a096-3cea78245340.png', '5bace529-66de-4eb0-bede-4da1c4aed9cd.png', 'a3f4d1b8-6de1-4631-a4f7-b7950c17cd05.png', '449547df-d691-4032-870d-e37732eb809d.png', 'fc8f23cb-b428-4f6f-b521-4211067f2901.png', '1a623a18-bf08-4204-8ed6-cd9e02edfbe1.png', '8263fd36-1344-4daa-8783-35c639ea5a9c.png', 'd7fb8ebf-3f08-401e-93cd-b149da0f0776.png', '7be94ac4-d568-453b-87eb-9826b226c4b1.png', 'ba56174f-98a1-4e80-b040-7edf29f8db86.png', '9d5b8701-9073-4cac-a1fd-c80a6d1404a7.png', '6c5784c1-91f9-4339-921b-f654456bc9a1.png', '876b6810-5df3-45c8-9d5a-9e3cd1d59022.png', '7b3daf31-affa-4499-8443-58d7d6196ca4.png', '9c388222-9984-4394-9039-dea9003ff490.png', 'fded8107-fee3-486d-83f7-3f145cc22da6.png', '4b9d409a-77c1-42a8-8594-3a20a875f28e.png', 'ec811ac3-19ca-4a43-990b-4e4704a7b649.png', 'c4475f02-eda4-48e8-904a-256e2291b300.png', 'efca1796-561c-4131-9a5d-19efe15f7e85.png', 'd894ff12-6d1c-4e18-a576-dd118a52f739.png', '53f0316b-563c-441b-a226-a369a0357dfe.png', 'a229390c-68af-40e5-a2d2-8d1abba22b69.png', 'ccfb61b2-a283-4024-8daa-f7273825a18f.png', '61547b57-720d-4423-9bd0-7c51351f22f2.png', 'd99949a0-341c-44f0-8ea9-290094ca6715.png', '799cabf9-90cd-4959-aaef-1b283f4d2a90.png', '64bc75a3-0dff-4194-97e2-71382a49a85d.png', 'd3ad2915-af30-426c-ad2d-1634df8c1b5f.png', '7c4047d8-0e2a-40d4-b85e-48480bfe5b92.png', '7ee4570e-5d4a-430a-a27f-e46381e08725.png', '18a72d07-25cf-4eb4-af6a-8a81e807bae6.png', '4d3f2ef9-9e30-4395-96cf-d44a2a976eb8.png', 'cc77d05d-ebcd-44a4-b1b9-ccd9f0bc9030.png', '983ff8e9-7b9a-40a3-910a-e43325b1ed5d.png', '6ab40f5f-0589-47f2-8029-cf4e7666ed17.png', 'c48497e9-8a9a-4af3-92bc-cb4bbfa5f19a.png', 'f5c2a165-7210-4db1-b467-1e30cbd606fd.png', '18cd05d0-f86e-4087-bdb1-36ae4307ba4c.png', 'faaa6a12-62d3-47bf-8138-d7b3a3c97629.png', '78a16aec-fc22-4ca6-8901-3bbf97652c07.png', '747f5ec4-265c-4470-a82d-eb8af41118b1.png', '34418371-837a-42d1-89fa-842508cfb742.png', '9c31e037-6327-4ba1-b001-ae4aa64e921a.png', 'e1f2638a-2e0f-4f09-87a5-e48efd23a2fb.png', 'cf31f348-a20a-45be-b5f5-44dfd84e0864.png', '5b46fd5b-d02a-4365-836e-cda3f45eb12c.png', 'd6fef463-081b-44eb-9dd2-4f7a0685058f.png', '82ae2fce-b936-4ec9-94f2-9f28fe845c8a.png', 'd4785e7d-1851-4347-8f23-5b0b9e1297d2.png', 'e3551a29-1582-44fe-9187-3c5a3e349750.png', '7873490b-1df2-4959-a095-862e921432c5.png', '535049a0-5af9-4cdb-8b37-cba346f91ec2.png', 'a90fa3b1-9f27-462b-8a1d-b2f9d89a78d1.png', '6f1bf8d9-2159-42e9-809e-5ab77ec4333b.png', '83272c3d-51d2-4c0e-9964-fafb76753126.png', 'e230bc06-3a33-49e3-955c-93eac7bf1847.png', '67506192-5dd6-4591-845a-1175ec7fb213.png', '112ef47f-9c95-442d-8e12-35755033f034.png', 'c71477d5-6afe-4225-9eeb-871b98c254af.png', '5cdfd11b-4f57-41c4-8c82-4490eb2fd2f9.png', 'e53ff4d0-6e02-4cce-a93f-f4a4361d582c.png', 'a5d3551e-12f8-478c-84b2-6bc609c03ed3.png', '3dcca19e-860f-4d58-84ae-51b5cd00adde.png', 'db637cd6-e969-46ec-bd38-e03eb835ac8a.png', '911fda2d-a2c6-4344-bc56-a42fdf3c1058.png', '51bd3238-9425-41ec-9919-79aa2b32e724.png', '01e16ddb-682d-4901-b56d-8686c4f9f976.png', 'f105587e-a2ae-46c8-a3b7-30d5120611f9.png', '48f302f9-b35e-42fa-9298-2563a0d9beb5.png', '85f6d0dd-980c-45df-a971-b3a8ac3213bd.png', 'e74bacd8-140c-4bb9-bec2-69fb52c6c9a1.png', '2f0f42a4-dc05-477c-91d2-fd7228d4844b.png', '8ec2e814-d1b7-47d9-aad3-070526a117ec.png', 'dab16c54-cd37-44a9-a3fd-55ed7fa8f30c.png', 'f8529eb0-34f1-4ea5-8c72-30fcb80eb33e.png', '12705828-047b-45cb-a8cb-4932ed887de1.png', '5fc756b1-4714-4631-b9e1-f365b59cd8d8.png', '3dc305bc-bb28-412d-9932-71f3f49d8905.png', '3cd1e997-7951-48ad-bd81-3fb055c252f9.png', '8c68d371-3917-4870-a063-d71e944657e5.png', '57220473-4988-4fc9-962b-5d1080e4a35b.png', '6ce2244e-e4ad-495f-9779-8c5cfd824199.png', 'fa315c5c-8444-4014-b4e5-ed21f891b251.png', 'b27d8243-f15a-4969-afa5-7fe443f28c4d.png', '93caa1a4-e457-4ac5-b1e3-c1b7cdfdac50.png', 'b9a77d83-e154-47a8-8191-bb6ae5842eae.png', 'd997dd45-fb25-44b1-a8d0-9febde2f4371.png', '382c6f6b-94fe-4f7d-97ce-466d93122d1b.png', '60bb6140-adcd-44b2-a8c9-35efc8b701bb.png', 'ea31d2cb-bc85-4b0b-8f7b-bb7ce1cee22d.png', '03cf39fd-692c-46db-80d2-f1efb09b0e31.png', '98fbc209-2453-4c01-a5f0-b1a0d72057b7.png', 'c99e0aac-6a3f-4773-9f16-a8a664cc3b58.png', '47d10903-9dff-4684-a05e-95ae4c6b8ba3.png', '71a4ce50-744f-49f2-8e17-6f39946b44f5.png', 'd40e61cf-8754-4367-a4dd-0e99cd1af0d0.png', 'b9081e46-c32d-4a93-9eeb-2eb9e195d0c5.png', 'fe9ba80f-ccb3-4de8-9f6b-610f814067d2.png', 'cce09464-cb24-46c7-9941-b05119e3456b.png', 'f4ed7271-d4b8-4bbd-a084-2728e2ef0253.png', '3e419ab7-df12-4f8f-9e6c-ce49e3c95a4c.png', '9e030d59-a98d-4ab2-8870-bdf1499b2bd8.png', '5d26f70c-8d1f-4a15-a618-c28ae3323c1a.png', 'f0a7cd05-0148-44f7-b102-6cc1c21107a7.png'}\n",
      "{'cf81cc61-16b5-496f-999d-d34b434a9cde.png', '4a699c93-97ed-4b6e-b36b-e58088eb24e4.png', 'd60b0cba-c1bd-4741-86ef-c24760605b03.png', 'b4abc0a4-600c-4834-bd71-c9dbb21eaaf0.png', 'be309060-220f-445f-9aa5-4a8825783fb2.png', 'ff3258f3-2c66-40cf-9d5d-fe77f8036fa6.png', 'e09d1d80-ae35-426e-870f-56421e61c48c.png', '70df055d-95ca-4ea1-bae5-d98a6a17aecc.png', '656ac314-64a2-4281-8a08-6596c5c5a20e.png', '00f08de1-517e-4652-a04f-d1dc9ee48593.png', '085a25eb-1ebd-4bf1-b320-7833e7c37553.png', '7e7765a1-8baa-4c1b-abdd-34113781994d.png', '01be392f-a46d-4aef-a57e-9cd1a80dd47e.png', 'b434200b-248e-4aa3-aeff-b0c9351a65fc.png', '3b7bd8bb-27f4-4416-9c4b-d68c4065aa54.png', '8e2b2c4e-18b8-4a78-8817-b1e8a1a5f32e.png', 'f40ba5da-1ef0-49d4-bb19-492892b41704.png', '3ed830ca-6746-47e8-b91e-0cfeeff9f9d2.png', 'c31be560-cec0-4ada-b2e1-be51c2e8bb22.png', 'ccfe0d0f-f75e-48ef-b754-4c2030a94c7b.png', '8609c224-17bc-4886-a08f-d82e098fe891.png', '15cc8c22-055e-4e64-8c5f-38816f82daa0.png', '8a0d16d4-5824-4bd6-a6b9-987e2bf71f3c.png', 'd98964c9-e676-4e33-a456-27cea6ff007a.png', 'fe2bc588-c737-464b-ad90-ed4e76f6c2ce.png', '165e4595-deeb-4910-b06b-89e2fba035f6.png', 'f9405a63-3a1b-4cc5-8f00-7b0a81c36a71.png', 'a4e7b487-c516-4e48-a31e-8b21e0a18117.png', 'a2a84bc3-c75b-4df6-840d-e118b61594d4.png', '48029094-265a-43e6-9e29-455237085578.png', '08542d41-e606-41df-b08c-9527b531f13f.png', 'ac88c984-77c4-4407-ac9b-157861501eec.png', 'a8098820-9876-4866-91b5-6ee9f91d106d.png', '0c0da1cf-9514-4c21-9988-fb53c52528d1.png', 'ccee655e-89d0-4ff8-b16e-33b214b08daf.png', '8bcaf61e-7a7b-477e-9618-02c434998ffd.png', '193ebe3c-905d-4ee0-87c0-b72999547d3b.png', '13e0c332-c269-40a3-9026-02a0f11a4dbd.png', 'aa78c204-135e-4605-8310-7202c41e08cc.png', '3b411a6e-270d-48d6-a3db-fbb4635151dd.png', '644662c0-c18a-4f1e-bccf-f0b222d99f59.png', '33c24f1e-7526-4d84-a057-facdc540f22b.png', '13acd418-a94d-4b36-900d-c13b9bd048c9.png', '28dfbd38-b24a-4cfb-a355-34c226dd2aa2.png', 'b72afa3e-644b-479a-845d-14fe8351cdb0.png', '47ec1b70-a18d-4c98-a313-4999a4059742.png', 'a056f19b-06e5-47f8-9861-005b6dd08fc0.png', 'e38ab400-f316-4091-8316-ddaf0b75f4dc.png', 'f49074c2-e73d-4884-804e-a2caab37bcf9.png', '0ff5bf5b-6af7-4537-90d0-1c47058d0627.png', 'ad87f2f3-94d1-459a-83de-fe597d9f5d13.png', 'bb509940-e147-4ff1-806b-a82890182d5b.png', '3df8778b-822d-4cae-8f94-9fe156c601b7.png', '4bfc4e8c-ee7b-4997-bcdd-e0734cba30b9.png', '1c2fbe4f-6785-420d-a7ef-d81b84ff45ec.png', '15f49c72-0702-472d-aff2-4582682392f2.png', 'a940da0e-5033-4069-9318-0f675dfcfc16.png', '55bc511a-5207-4316-b23b-d7a78a47737f.png', 'f8cadc7e-6554-4967-89f3-d22e7bce757b.png', '09d2a8d3-3ef9-4e91-8abe-d1c127747905.png', '6db32359-5e81-4f10-b509-5c55e1f27654.png', 'dcba2f1b-d117-4c79-b329-6446bc21b45f.png', 'aadc5c44-f71c-4975-8946-d5e8b484441a.png', 'ba54e255-4d76-4f33-ab14-cbe9ac42c5a5.png', '584b8c84-e2e5-4a88-b650-d97308671fdd.png', '7092a623-6d2d-4ecb-abed-be46296c4d7e.png', 'a86617dd-c1b7-4a69-aff1-68537437cb93.png', 'd984ecfc-6b4b-4f39-9e66-c0b79a3d00f9.png', '17e0f44b-39d6-4e3f-abd0-066fd94ee6de.png', '3db7e979-5f97-4985-bf0c-cdea7951e246.png', 'c21157da-1f74-4966-ba4e-c144d8f5da2d.png', 'a69636c7-d292-4e42-9114-a5a1c1158086.png', 'e8a234b2-5e8d-4b53-8a44-17c46a3678eb.png', 'd0370ad5-e503-4826-be45-b710ffc5066f.png', '040a0743-f663-4746-8224-f0e3bacc7ba5.png', '06b52ffd-71b8-429a-a284-bb39240ed343.png', 'aa9d099a-3a55-4fc8-81c5-9963bd04e9f7.png', '1d57c801-71b4-49da-8933-2cabdc927fef.png', '59ceee49-67e6-4a01-99e4-98e554fa6794.png', '0499513a-5d48-4cf9-aac8-115e2a52fe1a.png', 'af37b2a0-1a31-46d0-b64c-a7a6e3cd2995.png', '9683c5bf-fd40-4716-b7a2-1927b1f13319.png', '7002c25e-83ce-4af1-9cdb-a9d4899d6104.png', '081a54bb-0144-4c22-9909-e3e45b15ff4c.png', '7759e7ae-641f-4504-b373-95a8763dc59a.png', '395cb95f-700c-4a77-89f1-dcbddf957552.png', 'c37d38fe-a11e-453a-88a5-5d919bf9f760.png', '85d53fe7-2778-4b82-bf1d-e1d8796be73e.png', '89492f31-d3a7-4e3f-b715-efa858eb1c8c.png', '9341907e-9b62-4197-a0b3-3ddd3c55a884.png', '7b94fc31-0735-4840-beb8-c685f22ec90b.png', '338907f5-8c8c-47e7-a57d-6c9eb5b4529b.png', '72f79a49-6208-4253-9094-8081308caffb.png', 'ebdce693-283b-462c-825e-a182c6063a85.png', 'd5277276-f8f8-40e9-b8e1-791cf5d96ac0.png', '99772300-b5be-44cf-b8a9-682247e5e8c7.png', '000db696-cf54-4385-b10b-6b16fbb3f985.png', '3766b0a6-1769-4d82-b081-fa53531de34e.png', 'b77669dd-8554-4531-9903-9719747fdb63.png', 'ae3ec9ec-d945-49c3-8172-d815347858d1.png', '0fe227eb-592b-4ae5-b050-e7573d423953.png', '38dee80a-f2e3-41f4-8a72-1f89f4a9c003.png', 'b5c3e1a0-d4ba-413f-b571-809ee8aedf19.png', 'a472a01d-2145-4d5f-bee6-588b785bf036.png', '3dcc0fa9-312e-427f-9a03-132bcb72b3e0.png', '7cc95413-c3e4-45ef-b047-4021529fbdb4.png', 'b76086b3-9550-44f9-a2a8-394c7793bac8.png', '3ddfe89f-2b00-49cc-ad50-30ac45c8aad2.png', '1923df31-e23a-4ee4-86f8-35d124af2f61.png', 'e2e0accf-73b4-4cc4-bc85-2066f1fa4762.png', '48235c65-9a41-426c-b695-a01590d15333.png', '7507bb99-a8cf-48c8-a4dd-859ad26e9e1a.png', 'c3b96528-c441-4ae7-8e7f-87ccb0ab2ab9.png', 'f1677417-36ca-4ee2-886b-bb5e7c6a35ab.png', '6d0b86ac-4d99-4a45-8558-20de59ad39b0.png', 'c1da2ddd-0e40-4021-972c-67dc048bf353.png', 'd0d8cd7e-2abe-4f56-a9d9-938262605fee.png', 'd4304d61-7dec-4de2-83fa-7f6c9a09c5d4.png', '20f39b8e-be82-4f24-8791-651533a73184.png', '6e66dd4c-d183-42c7-ad77-32abf6ca9760.png', '4f4289e7-3e09-4934-ab15-bd5c25546061.png', 'd5d7c95e-0682-4b93-bf0b-5dff2fa91a92.png', '729c9ee1-d716-4b76-b5e7-690d6e914ea8.png', '228b3dc1-f78a-4ac9-b213-2a416583d063.png', '7a0105da-41e6-4500-8626-fb6e8f0dac5a.png', 'feb8dd3e-ecfc-493f-9094-00331a043c7c.png', 'b84cd9ad-7357-47f3-910e-626667c183e5.png', '71131596-6768-4832-a4b4-5b7a1478d060.png', 'b468a5c0-3e86-46d9-84f1-8a0dea47c854.png', '989620ed-615e-47a9-a2be-402c3b6f937e.png', 'c907dcd1-6011-430b-9515-009900b4a98f.png', '51e9d4d8-3c7e-4ad2-95ce-22aa2ff7da7e.png', '13932109-fbd1-4b6b-b81c-91682740cc50.png', 'f743c21e-5876-460b-bbd6-2e2dcca41baa.png', '86936d5f-73fb-462e-bcbc-5815879cb3d6.png', '742365a8-d9a5-41e4-b8a3-24a03a894f9f.png', '94c76c85-6c36-4c63-bb12-704c4cdd422f.png', 'b4f8176e-a3a7-4a9e-90ad-f2b80ac60e33.png', 'd979af2c-4ed0-42da-9b2d-5cd3733b8d13.png', '97d33835-1ad8-4c7b-8fce-4552d9dbe2f4.png', '9ca9ffa9-4810-4ed4-b919-39b2315ed461.png', 'c21d91c2-1444-4398-a5f7-4044d8e7f75c.png', 'bbcf427f-7155-4a51-b4f9-0797380e8e58.png', '72290038-af8f-4ebc-ae08-1cbb558ada40.png', '72dfb20b-bace-4888-85b5-22646ca74a28.png', '5711b0c6-2b21-4b72-b036-c1b3160cb6b4.png', '1a062886-29be-4120-92f3-5c1c8a951959.png', '6917d6dc-90c7-47cc-8169-f02d0df8a0aa.png', '65b87566-709e-4b0f-b4bb-55020515f6e7.png', 'f650ee02-3a03-4da0-8fd9-12f1ffae35b4.png', 'b03867f9-6a0e-4115-ac46-ed96db6b6644.png', '9a1fd0e4-262e-4856-85ba-88faf8b88726.png', '205f5b04-b42a-4890-af36-0ed2de7a56a1.png', 'f59ae80d-d98e-465f-963a-1064764211f8.png', '07332989-6518-4bd9-96de-f4513948cf4a.png', '9b838133-a269-416a-a0b5-9dc3ea7d585e.png', 'ec53eccf-e4e5-4151-b50b-d103e799a1f2.png', '18dea804-4283-4c5c-94ea-47c42bbb619e.png', '8a36f06f-80b0-43d6-8dcf-391e49587ebc.png', 'f6be6dc3-9539-46c0-a1f5-b10919ff81cd.png', 'e063b161-8c89-4324-92df-d99acbe65aa2.png', '660f30ba-71a2-4066-a469-0aeacd155d2c.png', 'd9728525-2c4b-4526-bbf7-873831872a20.png', '36b750d4-ac1c-4301-addb-bb00f6edad82.png', '69a4ab5a-da8a-4a93-9d83-801a700003e8.png', 'fad80315-158c-4399-b3b2-bee20c35863d.png', 'b1e7b5cd-f1b6-400d-b62a-57e6c45c663b.png', '1623088d-9f8c-4910-b681-c81fef043fa3.png', 'f92793eb-6396-4597-ad39-2cc6e8eff84b.png', 'f759e4b7-21fe-4f3a-aaeb-0b8b99cb103c.png', '427412d0-cf4c-4a13-b58e-6ffdd004c6ec.png', '637b1dfe-c876-44d8-b5a9-e5ebe3663773.png', 'b5ea0a2e-1122-4183-931c-8027caf1eb8d.png', '2c7411ab-ce18-469d-868f-de850cafa9ba.png', '60370334-2b17-4c9d-a05b-b5746bdaa3b1.png', '11fcbe52-87f7-4074-85ac-153d5f255e35.png', '32b9ab38-2dc3-471b-87d8-4a67f49bfb7c.png', '8dee40b1-4d3a-4d8b-853d-5651925b0ffa.png', '05d3817a-5535-4e77-8dda-d4412e496c81.png', '401afe9b-4c20-41cc-b52d-21995c71e872.png', 'ebc03c6f-4bed-4b0b-a283-f0624a9955cd.png', '9a75986a-bb57-4f82-b9cc-af6a5a9ea8c6.png', '18e8b809-d2a0-4749-a4a4-23b1f4881839.png', 'baac5ed4-b582-4c80-bd2d-acb97c52806e.png', '51c42643-1a55-4d9f-b9cb-1fd6846b22d3.png', '7b3e032d-e3ec-4c61-8a49-785fd6d0d87e.png', 'fcb06a43-8652-4bbf-bdf8-bb961137302a.png', 'af33db14-7cd0-4a94-90a3-6d912c1b2d1f.png', '6cba26dc-51c2-4a3a-bbd7-3af8dd5bfd65.png', '6c3c8214-b6cf-4dc8-934a-56e5c7a82072.png', '6f3d76ce-9c4e-4e4c-b344-776d764e1be8.png', 'afc077be-f1dd-4a46-aa37-b1a478687264.png', '7508399d-307f-450d-8f47-f24930ad6fb6.png', '12ee00f1-d4ea-4546-a07c-d43280aca538.png', 'be5d92d6-f2b3-483c-842c-aff4571ee8a7.png', 'bf02deef-f65f-41ac-a126-48a4740e161e.png', 'b4747fef-5911-464e-9854-a54718d81867.png', '6804008c-94eb-4870-ba6e-b06514073e71.png', '331b086e-e4a6-44f9-aa82-aff072c27a7a.png', '757438a0-081e-45e5-9896-ba91f82d3055.png', '31ad19e6-fe6d-40da-b2cc-a0dc5554d79e.png', '04e9f692-f3d6-496b-ae0c-905137cc1f84.png', 'f0678ab1-7a59-46b9-ba2c-def9ad6b8d22.png', '0aa43663-a1f3-44cb-8ecc-9b36fbb0d778.png', '00a05408-8291-4231-886e-13763e103161.png', 'eadd2c1c-2e56-4392-85dc-2c4fe8a9d420.png', 'eab6d0b6-1bba-4c26-a208-507c54d14016.png', '8ec959f3-27f9-43dc-98d0-dfa7ddf7d9e9.png', 'f6cfde90-10de-4584-aed1-2a0ef8238b11.png', '830029b1-3429-48f3-b13d-c7c611865d6e.png', 'c23ecec2-d791-42fa-8abf-cb4c447f9c21.png', '8f202a05-d9d3-43c2-aa4b-0ab8939f0607.png', '1ac5f0e8-f431-4400-b3f5-4a2224e540b2.png', '3d04aef0-2bb8-4de2-a871-4c814bca5d9b.png', '6f988c8c-ad47-4694-b5c9-bf572cc7c23a.png', '3fa7ddd4-6491-4809-8a46-fdfc6931ca22.png', '711b8e6a-0406-4c61-8c13-3e90fd7ecba1.png', 'a662a526-362a-4c97-9407-3ac207c5ba81.png', 'baed4093-ba48-42d5-8479-92b2612217e0.png', '905fcc4a-7a63-4326-9e55-2e8a9ecf1d9c.png', '098906c5-cf22-43d3-9f0d-90e88e602090.png', 'b8d6b40d-2a3d-475f-88d3-03560f645223.png', 'bc87d74c-9d22-4046-ae17-5891adfa0b41.png', 'bb7dca62-6180-4e52-81b6-8a9e09a4bfae.png', 'fd676e0b-14e6-40d4-8c4a-85d028559ad1.png', '8dac50e2-b384-42f6-b05f-80347f7d30a9.png', 'abc5356a-b8b2-4a0b-9dab-14c54efb4f29.png', '7202cb18-cb1d-45eb-9060-207d4cd52b9e.png', '083a1a20-f642-42e3-b20b-937383f6da3c.png', 'ab71b558-cd1c-4ca8-b06e-05b4f3f48525.png', '9ed655dd-cc93-4bde-be51-804bac051f25.png', '4f781277-d540-4cd6-b405-4f215281d78e.png', '7f9b4539-9cfb-49db-9d19-dea98ab6445f.png', 'ec525238-c296-4a6d-a351-ce760c7111d9.png', 'aeb2a32c-595a-44c2-b827-c6ce0f6ff4f3.png', 'b8fbe64b-f29f-4c6e-9b4e-999d69719ab8.png', 'b99dd9a2-7611-4752-a972-11a231a1deaf.png', 'f7bd2b79-ca7e-4787-9d78-7041d7aa7498.png', '2017d9e5-6f8b-42f0-97e1-ac5d29f9de60.png', 'ddb4f535-9e42-420a-9851-3fb6a06a0143.png', '73d61c35-605f-435e-af98-5cc68b188a46.png', 'b38eb728-d36c-457e-a05c-c81a6d28edf8.png', '6aa4fb59-0bea-40b9-9c66-83199d91714e.png', 'a8935cae-155c-4200-afc5-6fd74dd1b31b.png', 'a797f1b9-aa61-4ee3-91f2-e8a823d42b1a.png', 'f630809e-2498-44af-beaa-dda23a36cf20.png', '32827da4-939c-46de-85db-a2d75cb0dfad.png', '46b861c5-844c-40be-b390-63008b567261.png', '080f2b35-fcd5-473e-864b-a7dea3054cc7.png', '56f5bc59-c8a4-4cca-85b9-7b704532b3bd.png', 'f86a02d1-4ee2-4578-b001-a03952254643.png', '775c8468-399e-49a9-9fe4-07e75071abe7.png', '7c8f2458-3d40-4810-b57c-1f149c2c4d3c.png', 'f184f903-7ec4-4b69-8ac1-1f2d171065ef.png', 'c2ed72cd-0390-46c3-ac73-601b1a875d5d.png', '66a4d456-d66e-4341-aa83-b011427fd9de.png', '36f8833d-6bec-4307-af23-3908684ee79b.png', '4edadee3-ed63-4cb8-bced-20db6b38d0cc.png', 'fbea2dbf-3828-4b0b-a8cf-e1a1e513851b.png', '3c725c16-4631-429e-941b-3c797df3f901.png', 'f919d3cb-dc68-46b6-8c29-2d3914fbaec0.png', '591142fb-40d8-4c86-81e3-f6437d671c37.png', '24c876fa-93e4-4dd6-b1f1-a6f5f4aab729.png', '8ee69af3-04f7-4fb3-96a9-775c37234c4f.png', 'a36d17af-dcd7-4414-a701-3ef7c462e05e.png', '4703da4b-5d0c-416a-9ebe-39d1776bf593.png', '27b32500-40ef-4c14-ab88-ace5e9ceea27.png', '6d462751-b97f-48a1-b09c-192c5e114825.png', '79bb5ea3-ca6c-4d75-a379-a6ee6c6da659.png', 'b6628d2e-e8dc-427e-bcb4-a19cf31b9ec7.png', 'df0f59ce-d11a-488d-a51c-bd9105e592f6.png', '00c0b293-48e7-4e16-ac76-9269ba535a62.png', '85708ae1-d69e-4153-bdad-ced31dfaf486.png', '99a21978-b49a-403a-9424-5745a90c8018.png', 'b41dfb17-3773-485b-8da6-c29a2bbfbe3a.png', 'b1046f7e-c90f-4043-a678-087754decbd9.png', '9388011e-2250-40d3-be0e-39bc418d984b.png', 'c9e42d59-92ab-4e5f-a0fa-c728193684d4.png', 'b45e1b50-d497-4b91-9b79-5050fd0e6800.png', '8aa93e86-e189-4412-ba91-725813f54b56.png', 'bef4ff3a-6fb0-4213-a5a9-125eff87dc22.png', 'ad217b8d-1a8a-4347-871c-812febbde1e4.png', 'ac9106d5-8cbc-46b0-b27e-8c998b04ef51.png', 'e1d5a233-39ca-41dc-a289-b07c3e78cdb1.png', '3d57f7e9-b198-4478-84c4-063bea92b00e.png', '66ab31a6-be10-4f4e-ad4d-b4aeb9371271.png', '889672e3-66b7-4879-9b02-0bc41d3f66d2.png', '05bb6f8d-453b-4e56-ae92-2600e058ba65.png', 'f336113a-6002-41da-8451-997d62e36a34.png', 'f5544779-e6b9-456b-a475-867e41212602.png', '84909dca-4b86-43dd-8bba-d8fc06a85e15.png', '35e2f247-6930-4b7d-bc43-baaa622cce2c.png', '7e2246e4-8412-4216-af50-7ae8c232f9b9.png', 'b4a2cd51-7078-496c-9a4c-f0641ea9b13c.png', '32c9f801-2eaf-433b-a87b-08ab319ba27a.png', 'b13df066-d9eb-41d8-82c0-3fd56846a98f.png', 'c42f4515-1bf2-4f63-a815-fa2e5bd45016.png', '34956207-2ebf-4a47-bc56-faf23701adf2.png', 'b9c687bf-4fa5-447c-b526-24ea3ce3d6e2.png', '918762a3-791d-48f5-9b3b-9c149ed72264.png', 'bcc24ec7-8a99-4dcf-ba71-ac73659e2ac1.png', '372dc27b-20c5-418a-b09d-8816843e940e.png', 'c26c0bb6-125b-497f-a3fa-04a5729b36c0.png', 'c068a37d-3fe7-4a26-bb74-575ea6be194d.png', '51f540ba-aad8-4e1f-bc8b-7373d3d23ee2.png', '4a4be7b1-6a74-49d9-b0cb-d9aef48f990c.png', '3a146de9-9044-4abc-b15c-e7e0d18a0704.png'}\n"
     ]
    }
   ],
   "source": [
    "############### SAVE GOOD CLASSIFIED ADN MISCLASSIFIED IMAGES ###############\n",
    "guardar_misclassified_images(misclassified_no_as_pn, misclassified_pn_as_no, save_path_0, save_path_1)\n",
    "guardar_misclassified_images(good_classification_no_pneumo, good_classification_pneumo, save_path_1, save_path_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
